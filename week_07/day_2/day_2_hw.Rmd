---
title: "R Notebook"
output: html_notebook
---

# Homework: Time Series and Spatial 



```{r}
library(tidyverse)
library(lubridate)
library(tsibble)
library(tsibbledata)
library(fable)
```


1. Load in the nyc_bikes data from the tsibbledata package. Have an initial look at it to see what you’re working with. Create three new columns: one that stores only the year the bike was used, one that stores only the month the bike was used, and one that stores the date. Use the data stored in start_time to create these new columns.
```{r}
nyc_bikes 

nyc_bikes <- nyc_bikes %>% 
  mutate(year_used = year(start_time), 
         month_used = month(start_time), 
         date_used = date(start_time))
```



2. Summarise the number of bike hire counts by month. Make a plot of this data. *Hint: remember that to group time series (tsibble) data, you need to use index_by instead of group_by before your summarise function. What does this plot tell you about the time series? Do you think this downsampled data would be adequate to build a forecast with?

```{r}
nyc_bikes %>% 
  index_by(month_used) %>% 
  summarise(hires_per_month = n()) %>%
  ggplot + 
  aes(x = month_used, y = hires_per_month) + 
  geom_col(fill = "indianred") + 
  theme_fivethirtyeight()

#plot tells us that there is a clear spike in the summer months, and much less demand for bike hire in the winter 
```

3. Now Summarise the number of bike hire counts by date. Make a plot of this new aggregated data. What does this plot tell you about the time series? Would this data be preferrable for time series forecasting compared to the monthly data?

```{r}
library(ggthemes)

nyc_bikes_date_sum <- nyc_bikes %>% 
  index_by(date_used) %>% 
  summarise(hires_per_day = n()) 


  ggplot(nyc_bikes_date_sum) + 
  aes(x = date_used, y = hires_per_day) + 
  geom_line(col = "indianred") + 
  theme_fivethirtyeight()
  
#its preferable because it gives a finer grained picture of the differences in bike hires
  

```


4. Let’s begin to build a model. For this, we will test the NAIVE, MEAN, and SNAIVE model. However, the first thing you’ll notice when you try and build a model is that you get an error: 

Into q 5


```{r}
nyc_bikes_sans_gaps <- nyc_bikes_date_sum %>% 
  fill_gaps(hires_per_day = as.integer(median(hires_per_day)))

fit_hires_pday <- nyc_bikes_sans_gaps %>% 
  model(snaive_model = SNAIVE(hires_per_day), 
        naive_model  = NAIVE(hires_per_day), 
        mean_model = MEAN(hires_per_day))

forecast_dayhires <- fit_hires_pday %>% 
  forecast(h = 120)

forecast_dayhires %>% 
  autoplot(level = NULL) + 
  autolayer(nyc_bikes_sans_gaps, colour = "black") + 
  theme_minimal()
```

6. Test your model accuracy : choose a training data set from your main dataset, build a forecast on the training set, and then plot the training set forecast against the real data. Calculate model accuracy.

```{r}
library(tidyverse)
nyc_bikes_sans_gaps

#creating my training data: decided to use data from january till end of sep: then test it on the october - december data 
training_bikes <- nyc_bikes_sans_gaps %>% 
  filter_index("2018-01-01" ~ "2018-09-30")


#run model on training data 

fit_training <- training_bikes %>%
  model(snaive_model = SNAIVE(hires_per_day), 
        NAIVE_model  = NAIVE(hires_per_day), 
        mean_model = MEAN(hires_per_day))


#create forecast with training model 

forecast_training <- fit_training %>%
  forecast(h = 92)

#now gonna visualise this model and plot it against the actual data 

forecast_training %>% 
  autoplot(training_bikes) + 
  #now can add in the actual data 
  autolayer(nyc_bikes_sans_gaps, color = "black") +  
  theme_minimal()


forecast_training %>% 
  autoplot(training_bikes, level = NULL) + 
  autolayer(nyc_bikes_sans_gaps, color = "black")
```




```{r}
accuracy_model <- accuracy(forecast_training, nyc_bikes_sans_gaps)

accuracy_model
```

7. Look at your forecast plots and accuracy values. Describe your results. Are your models a good fit for the data? If not, why not? What would you suggest doing with the data if you were expected to present these back to a client? For example, would you ask for more data? Would you test a different model?



So the models aren't a great fit to the actual data from the look of it. Also, the model fits aren't great (but i'm not that sure how to interpret them yet). My predicted data is not a good match to the actual data. There is clearly not enough data to create a good prediction from. My model predicts very little monthly/weekly variation - but seems to get overfit daily variation. 








8. Make a simple ggplot (geom_point) which plots the start longitude and latitudes of each bike. Create a separate facet for each bike_id. Colour the dots in by month of use. What does this tell you about what month each bike was used most in?

Do the same for the end longitude and latitudes.



```{r}
head(nyc_bikes)
```

```{r}
nyc_bikes %>% 
  ggplot + 
  aes(x = start_long, y = start_lat) + 
  geom_point() 
```




```{r}

library(ggthemes)

nyc_bikes %>% 
  ggplot + 
  aes(x = start_long, y = start_lat, col = month_used) + 
  geom_point() + 
  facet_wrap(~ bike_id) + 
  scale_color_distiller("PuOr") + 
  theme_fivethirtyeight()

```

```{r}
nyc_bikes %>% 
  ggplot + 
  aes(x = end_long, y = end_lat, col = month_used ) + 
  geom_point() + 
  facet_wrap(~ bike_id) + 
  theme_minimal()
```

9. Create an interactive leaflet plot which plots the start points of the city bikes. Ensure it has at least markers to denote start points (taken from the nyc_bikes_spatial data). Feel free to add any additional features you wish.

```{r}

library(leaflet)

nyc_bikes_spatial <- nyc_bikes %>% 
  select(start_lat, start_long, bike_id)



bike_start_point_map <- leaflet(nyc_bikes_spatial) %>%
  addTiles() %>%
  addCircleMarkers(lng = ~ start_long, lat = ~ start_lat, opacity = 1, fillOpacity = 0.01)

bike_start_point_map


```









